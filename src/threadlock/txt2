16.1 How would you measure the time spent in a context switch?
this is a tricky question, but let's start with a possible
solution.
a context switch is the time spent switching between two 
processes(i.e., bringing a waiting process into execution
and sending an executing process into waiting/terminated
state). This happens in multitasking. The operating system
must bring the state information of waiting processes into
memory and save the state information of the currently running
process.

In order to solve this problem, we would like to record
the timestamps of the last and first instruction of the swapping
processes. the context switch time is the differentce in the 
timestamps between the teo processes.

Let's take an easy example: assume there are only two 
processes, P1 and p2.

p1 is executing and p2 is waiting for execution. at some
point, the operating system must swap p1 and p2-let's assume
it happens at the Nth instruction of P1. If tx,k indicates the
timestamp in microseconds of the kth instruction of process x,
then the context switch would take t2,3-t1,n microseconds.

the tricky part is this: how do we know when this swapping occurs?
we cannot, of course, record the timestamp of every instruction
in the process.

another issue is that swapping is governed by the scheduling algorithm
 of hte operating system and there may be many kernel level
 threads which are also doing context switches. other processes could
 be contending for the CPU or the kernel handling interrupts. other processes
 could be contending for the CPU or the kernel handling interrupts.
 the user does not have any control over these extraneous
 context switches. For instance, it at time t 1, n the kernel
 decides to handle an interrupt, then the context switch time
 would be overstated.
 
 In order to overcome these obstacles, we must first construct 
 an environment such that after p1 executes, the task scheduler 
 immediately selects p2 to run. this may be accomplished by 
 constructing a data channel, such as a pipe, between
 p1 and p2 and having the two processes play a game of ping-pong with 
 a data token.
 
 that is, let's allow p1 to be the initial sender and p2 to be
 the receiver. Initially, p2 is blocked (sleeping) as it awaits the data
 token. when p2 executes, it delivers the token over the data channel to p2 and
 immediately attempts to read a response token. However, since p2
 has not yet had a chance to run, no such token is available for p1 and the 
 process is blocked. this relinquishes the CPU.
 
 a context switch results and the task scheduler must select another process to run.
 since p2 is now in a ready-to-run state, it is a desirable candidate to 
 be selected by the task scheduler for execution. when p2
 runs, the roles of p1 and p2 are swapped. P2 is now acting
 as the sender and p1 as the blocked receiver. the game ends
 when p2 returns the token to p1/
 
 to summarize, an iteration of the game is played with the following steps:
 
 1, p2 blocks awaiting data from p1.
 2, p1 marks the start time
 3, p1 sends token to p2
 4, p1 attempts to read a response token from p2. this induces a context switch
 5, p2 is scheduled and receives the token
 6, p2 sends a response token to p1.
 7, p2 attempts read a response token from p1. this induces a context switch.
 8, p1 is scheduled and receives the token.
 9, p1 marks the end time.
 
 the key is that the delivery of a data token induces a context switch.
 let Td and Tr, be the time it takes to deliver and receive a data token,
 respectively, and let Tc be the amount of time spent in a 
 context switch. at step 2, p1 records the timestamp of 
 the delivery of the token, and at step 9, it records the 
 timestamp of the response. the amount of time elapsed, T,
 between these events may be expressed by:
 T=2*(Td+Tc+Tr)
 
 this formula arises because of the following events:
 p1 sends a token (3), the CPU context switches(4), p2 receives it (5). then sends the 
 response token (6), the CPU context switches(7), and finally
 p1 receives it (8).
 
 p2 will be able to easily compute T, since this is just the time
 between events 3 and 8. So, to solve for Tc, we must first determine the 
 value of Td +Tr.
 
 how can we do this? we can do this by measuring the length
 of time it takes p1 to send and receive a token to itself.
 this will not induce a context switch since p1 is running on 
 the CPU at the time it sent the token and will not block
 to receive it.
 
 The game is played a number of iterations to average out
 any variability in the elapsed time between steps 2 and 9
 that may result from unexpected kernel interrupts and 
 additional kernel threads contending for the CPU. we select
 the smallest observed context switch time as our final answer.
 
 however, all we can ultimately say that this is an approximation 
 which depends on the underlying system. For example, we make
 the assumption that p2 is selected to run once a data
 token becomes available. however, this is dependent on the
 implementation of the task scheduler and we cannot make 
 any guarantees.
 
 that's okay; it's important in an interview to recognize when
 your solution might not be perfect.